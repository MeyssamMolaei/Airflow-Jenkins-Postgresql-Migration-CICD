apiVersion: v1
kind: Service
metadata:
  name: airflow
spec:
  type: NodePort
  ports:
    - port: 8080
      targetPort: 8080
      nodePort: 30080
  selector:
    app: airflow
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow
spec:
  selector:
    matchLabels:
      app: airflow
  template:
    metadata:
      labels:
        app: airflow
    spec:
      containers:
        - name: airflow
          image: apache/airflow:latest
          command: ["airflow", "standalone"]
          env:
            - name: AIRFLOW__CORE__LOAD_EXAMPLES
              value: "False"
            - name: AIRFLOW_CONN_POSTGRES_P1
              value: "postgresql://postgres:p1password@postgres-p1:5432/source_db"
            - name: AIRFLOW_CONN_POSTGRES_P2
              value: "postgresql://postgres:p2password@postgres-p2:5432/target_db"
            - name: AIRFLOW__API__AUTH_BACKENDS
              value: "airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session"
          ports:
            - containerPort: 8080
          volumeMounts:
            - name: dags-volume
              mountPath: /opt/airflow/dags/db_sync.py
              subPath: db_sync.py
      volumes:
        - name: dags-volume
          configMap:
            name: airflow-dags
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-dags
data:
  db_sync.py: |
    from airflow import DAG
    from airflow.operators.python import PythonOperator
    from airflow.providers.postgres.hooks.postgres import PostgresHook
    from datetime import datetime, timedelta

    def sync_data():
        src_hook = PostgresHook(postgres_conn_id='postgres_p1')
        src_conn = src_hook.get_conn()
        src_cursor = src_conn.cursor()

        dest_hook = PostgresHook(postgres_conn_id='postgres_p2')
        dest_conn = dest_hook.get_conn()
        dest_cursor = dest_conn.cursor()

        src_cursor.execute("SELECT id, name, department, salary FROM employees")
        rows = src_cursor.fetchall()

        dest_cursor.execute("""
            CREATE TABLE IF NOT EXISTS employees (
                id SERIAL PRIMARY KEY,
                name VARCHAR(100),
                department VARCHAR(100),
                salary NUMERIC
            )
        """)
        
        dest_cursor.execute("DELETE FROM employees")
        
        for row in rows:
            dest_cursor.execute(
                "INSERT INTO employees (id, name, department, salary) VALUES (%s, %s, %s, %s)",
                row
            )

        dest_conn.commit()
        src_cursor.close()
        src_conn.close()
        dest_cursor.close()
        dest_conn.close()

    default_args = {
        'owner': 'airflow',
        'start_date': datetime(2023, 1, 1),
    }

    with DAG(
        'postgres_sync_p1_to_p2',
        default_args=default_args,
        schedule_interval=None,
        catchup=False,
    ) as dag:
        sync_task = PythonOperator(
            task_id='sync_employees',
            python_callable=sync_data,
        )
